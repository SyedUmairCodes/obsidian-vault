# Responsible AI

Responsible AI is the ethical development and use of AI with the intention of benefiting people and society, while avoiding harm. It requires awareness of AI's limitations and a commitment to using it ethically. AI users are those who use AI to complete tasks, and while AI can make work more productive, it is not perfect. Humans possess critical reasoning abilities and contextual understanding that AI systems lack. AI should be used to complement human skills, not replace them.

## AI Bias

AI models are trained on data created by humans, which means they are subject to bias. AI models reflect the values of the people who design them and are not value-neutral.

- Systemic bias is when institutions favor certain outcomes or groups. This can affect the data used to train AI, even if the designers think the data is high quality.
- Data bias is when errors or prejudices lead to unfair or inaccurate information, resulting in biased outputs.

## AI can be harmful

AI can cause several types of harm if used irresponsibly:

- Allocative harm is when AI withholds opportunities, resources, or information that affects a person's well-being. This can lead to people being denied access to resources.
- Quality-of-service harm is when AI tools don't perform as well for certain groups of people based on their identity.
- Representational harm is when AI reinforces the subordination of social groups based on their identities.
- Social system harm refers to macro-level societal effects that amplify existing disparities or cause physical harm. This includes the spread of disinformation like deepfakes.
- Interpersonal harm is the misuse of technology to create a disadvantage to certain people that negatively affects relationships or causes a loss of one's sense of self.

## Privacy and Security

Privacy is the right to control how personal information is collected, stored, and used. Security is the act of safeguarding personal information and private data and preventing unauthorized access.

- AI tools use data sets and user inputs, which can include private information.
- Using AI tools can present security risks, and organizations should put enhanced measures in place before using generative AI.
- Users should be aware of an AI tool's terms of use, privacy policy, and risks.
- Users should avoid inputting personal or confidential information into AI tools.
- Users should stay up to date on the latest AI tools to understand risks.

## Related Notes